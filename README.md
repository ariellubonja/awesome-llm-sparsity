# awesome-llm-sparsity

Collection of papers, algorithms, and other resources that show how sparsity emerges in LLMs, and how it can be utilized to optimize them


## Emergent Sparsity

| Paper | Code | Date |
|:----|  :----: | :---:|
|[The Lazy Neuron Phenomenon: On Emergence of Activation Sparsity in Transformers](https://arxiv.org/pdf/2210.06313.pdf) @ Google | ∅ | June-23
|[ReLU Strikes Back: Exploiting Activation Sparsity in Large Language Models](https://arxiv.org/pdf/2310.04564.pdf) @ Apple | ∅ | Oct-23
<br/>


## Sparse Transformers


| Paper | Code | Date |
|:----|  :----: | :---:|
|[Learn To be Efficient: Build Structured Sparsity in Large Language Models](https://arxiv.org/pdf/2402.06126.pdf) @ UIUC, CMU | ∅ | Feb-24
|[Generating Long Sequences with Sparse Transformers](https://arxiv.org/pdf/1904.10509.pdf) @ OpenAI | ∅ | Apr-19
<br/>


## Reviews


## Awesome Related Repos

[Awesome-Efficient-LLM](https://github.com/horseee/Awesome-Efficient-LLM)
[Awesome-LLM-Inference](https://github.com/DefTruth/Awesome-LLM-Inference)

<br/><br/><br/>

Thanks to [horseee](https://github.com/horseee/Awesome-Efficient-LLM/blob/main/README.md?plain=1) for the table!

